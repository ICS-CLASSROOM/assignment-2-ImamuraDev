{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b2038d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1443cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b0d3e6",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "\n",
    "In this first part, we're going to use Spark to analyze the following books, which Iahev downloaded from Project Gutenberg and saved to the data folder.\n",
    "\n",
    "| File name | Book Title|\n",
    "|:---------:|:----------|\n",
    "|43.txt | The Strange Case of Dr. Jekyll and Mr. Hyde by Robert Louis Stevenson|\n",
    "|84.txt | Frankenstein; Or, The Modern Prometheus by Mary Wollstonecraft Shelley |\n",
    "|398.txt  | The First Book of Adam and Eve by Rutherford Hayes Platt|\n",
    "|3296.txt | The Confessions of St. Augustine by Bishop of Hippo Saint Augustine|\n",
    "\n",
    "Our objective is to cluster these 7 books based on thier similarity in terms of their most frequent context specific words, i.e. note \"the\", \"and\", \"or\", etc..\n",
    "\n",
    "* One we've generated those workds for these 7 works, we will use those vectors to generate a hierarchical clustering for that shows the simialrity between these books.\n",
    "\n",
    "For this assignment, you will need to make sure you're running from a PySpark docker environment I introduced in class. You can start the docker pySpark docker environment using the following command:\n",
    "\n",
    "```\n",
    "docker run --rm -p 4040:4040 -p 8888:8888 -v $(pwd):/home/jovyan/work jupyter/all-spark-notebook\n",
    "```\n",
    "\n",
    "Make sure you run the command from the directory containing this jupyter notebook and your data folder.\n",
    "\n",
    "\n",
    "</b>\n",
    "# WARNING: For some reason, the document didn't always sync properly what I was pushing to github. I suspect it had something to do with running in a mounted volume in Docker. As such, I strongly encourage you to push often and to check that the document synced properly to github\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ecd48e",
   "metadata": {},
   "source": [
    "### Prologue\n",
    "\n",
    "An important aspect of Natural Lanaguge Processing is the identification of texts that are similar. A naive approach to decide whether two documents are similar is by treating  a book as a collection of words (or, bag of words) and compare the documents based on these words. For example, one would expect two books the topic of which is religion  (ex. books 398.txt and  3296.txt), to have more words in common that words than a book that talks about religion and a book that discusess science fiction (ex books 84.txt and 398.txt). \n",
    "\n",
    "As mentioned above, we will be using Spark to analyze the data. While Spark is not necessary for such a small example, the plateform would be idea for analyzing a very large collection of documents, such those are often handled by large comapnies\n",
    "\n",
    "This part of the assignment will rely exclusively on RDDs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a15530",
   "metadata": {},
   "source": [
    "QX. We'll start by importing Spark and making sure our environemnt is set up properly for the assignment.\n",
    "\n",
    "Import the spark context necesarry to load a document as an RDD\n",
    "\n",
    "* Ignore  any error messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e80df4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "sc.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336d5c9d",
   "metadata": {},
   "source": [
    "QX Read in the file `43.txt` as a spark RDD and save it to the variable book_43\n",
    " * make sure book_43 of type MapPartitionsRDD\n",
    "   * str(type(book_43)) == \"<class 'pyspark.rdd.RDD'>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d4164f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_43 = sc.textFile('data/43.txt')\n",
    "str(type(book_43)) == \"<class 'pyspark.rdd.RDD'>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8c051e",
   "metadata": {},
   "source": [
    "QX How many lines does `book_43` the file contain?\n",
    "* You can only use operarations or actions to answer the question. \n",
    "  * Code that uses methods such as `some_rdd.X().Y().Z()...` is allowed\n",
    "  * Code that uses function such as `some_func(...)` is not allowed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3c5a06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2935"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_43.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca2bc6d",
   "metadata": {},
   "source": [
    "QX We need to first remove the occurrences of non-alphabetical characters and numbers. You can use the following function, which given a line, remove digist and non-word characters and splits it into a collection of word \n",
    "\n",
    "```python\n",
    "def clean_split_line(line):\n",
    "    a = re.sub('\\d+', '', line)\n",
    "    b = re.sub('[\\W]+', ' ', a)\n",
    "    return b.upper().split()\n",
    "```\n",
    "\n",
    "Use the fucntion above on the variable (test_line) to see what it returns.\n",
    "```python\n",
    "test_line = \"This is an example of that contains 234 and a dash-containing number\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55ce2754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'an',\n",
       " 'example',\n",
       " 'of',\n",
       " 'that',\n",
       " 'contains',\n",
       " 'and',\n",
       " 'a',\n",
       " 'dash',\n",
       " 'containing',\n",
       " 'number']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_split_line(line):\n",
    "    line = re.sub('\\d+', '', line)\n",
    "    line = re.sub('[\\W]+', ' ', line)\n",
    "    return line.split()\n",
    "test_line = \"This is an example of that contains 234 and a dash-containing number\"\n",
    "clean_split_line(test_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e951e5",
   "metadata": {},
   "source": [
    "QX How words does this book contain.  To answer this question, you may find it useful to apply the function in a spark-fashion. \n",
    "* You can only use operarations or actions to answer the question. \n",
    "  * Code that uses methods such as `some_rdd.X().Y().Z()...` is allowed\n",
    "  * Code that uses function such as `some_func(...)` is not allowed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99c1b93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29116"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_43.flatMap(clean_split_line).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d62952",
   "metadata": {},
   "source": [
    "QX How many of the words in book_43 are unique. Given that words can appear in any case (ex. The, THE, the), make sure you convert the words into lower case (arbitrarily seleted).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07785c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project',\n",
       " 'gutenberg',\n",
       " 'ebook',\n",
       " 'of',\n",
       " 'strange',\n",
       " 'mr',\n",
       " 'hyde',\n",
       " 'robert',\n",
       " 'stevenson',\n",
       " 'this',\n",
       " 'is',\n",
       " 'use',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'in',\n",
       " 'united',\n",
       " 'other',\n",
       " 'world',\n",
       " 'at',\n",
       " 'no',\n",
       " 'restrictions',\n",
       " 'whatsoever',\n",
       " 'may',\n",
       " 'give',\n",
       " 'away',\n",
       " 'online',\n",
       " 'www',\n",
       " 'org',\n",
       " 'are',\n",
       " 'have',\n",
       " 'check',\n",
       " 'country',\n",
       " 'where',\n",
       " 'before',\n",
       " 'using',\n",
       " 'title',\n",
       " 'october',\n",
       " 'language',\n",
       " 'set',\n",
       " 'encoding',\n",
       " 'utf',\n",
       " 'produced',\n",
       " 'widger',\n",
       " 'start',\n",
       " 'contents',\n",
       " 'story',\n",
       " 'search',\n",
       " 'was',\n",
       " 'quite',\n",
       " 'carew',\n",
       " 'murder',\n",
       " 'letter',\n",
       " 'last',\n",
       " 'night',\n",
       " 's',\n",
       " 'narrative',\n",
       " 'henry',\n",
       " 'full',\n",
       " 'statement',\n",
       " 'utterson',\n",
       " 'rugged',\n",
       " 'never',\n",
       " 'cold',\n",
       " 'scanty',\n",
       " 'discourse',\n",
       " 'backward',\n",
       " 'long',\n",
       " 'dusty',\n",
       " 'yet',\n",
       " 'somehow',\n",
       " 'friendly',\n",
       " 'meetings',\n",
       " 'when',\n",
       " 'wine',\n",
       " 'his',\n",
       " 'something',\n",
       " 'human',\n",
       " 'beaconed',\n",
       " 'indeed',\n",
       " 'way',\n",
       " 'into',\n",
       " 'but',\n",
       " 'spoke',\n",
       " 'only',\n",
       " 'these',\n",
       " 'symbols',\n",
       " 'after',\n",
       " 'more',\n",
       " 'loudly',\n",
       " 'acts',\n",
       " 'he',\n",
       " 'drank',\n",
       " 'gin',\n",
       " 'though',\n",
       " 'crossed',\n",
       " 'twenty',\n",
       " 'years',\n",
       " 'an',\n",
       " 'approved',\n",
       " 'tolerance',\n",
       " 'others',\n",
       " 'sometimes',\n",
       " 'envy',\n",
       " 'high',\n",
       " 'pressure',\n",
       " 'spirits',\n",
       " 'inclined',\n",
       " 'help',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'i',\n",
       " 'heresy',\n",
       " 'used',\n",
       " 'say',\n",
       " 'quaintly',\n",
       " 'let',\n",
       " 'brother',\n",
       " 'go',\n",
       " 'own',\n",
       " 'reputable',\n",
       " 'good',\n",
       " 'influence',\n",
       " 'downgoing',\n",
       " 'as',\n",
       " 'came',\n",
       " 'chambers',\n",
       " 'shade',\n",
       " 'change',\n",
       " 'feat',\n",
       " 'undemonstrative',\n",
       " 'best',\n",
       " 'even',\n",
       " 'seemed',\n",
       " 'similar',\n",
       " 'catholicity',\n",
       " 'mark',\n",
       " 'modest',\n",
       " 'circle',\n",
       " 'ready',\n",
       " 'opportunity',\n",
       " 'known',\n",
       " 'longest',\n",
       " 'like',\n",
       " 'growth',\n",
       " 'implied',\n",
       " 'aptness',\n",
       " 'distant',\n",
       " 'kinsman',\n",
       " 'nut',\n",
       " 'crack',\n",
       " 'two',\n",
       " 'subject',\n",
       " 'common',\n",
       " 'reported',\n",
       " 'them',\n",
       " 'walks',\n",
       " 'said',\n",
       " 'looked',\n",
       " 'dull',\n",
       " 'would',\n",
       " 'appearance',\n",
       " 'put',\n",
       " 'greatest',\n",
       " 'store',\n",
       " 'chief',\n",
       " 'week',\n",
       " 'aside',\n",
       " 'occasions',\n",
       " 'calls',\n",
       " 'business',\n",
       " 'chanced',\n",
       " 'rambles',\n",
       " 'led',\n",
       " 'down',\n",
       " 'quarter',\n",
       " 'quiet',\n",
       " 'drove',\n",
       " 'trade',\n",
       " 'weekdays',\n",
       " 'inhabitants',\n",
       " 'emulously',\n",
       " 'do',\n",
       " 'out',\n",
       " 'grains',\n",
       " 'coquetry',\n",
       " 'shop',\n",
       " 'fronts',\n",
       " 'stood',\n",
       " 'invitation',\n",
       " 'smiling',\n",
       " 'saleswomen',\n",
       " 'veiled',\n",
       " 'charms',\n",
       " 'contrast',\n",
       " 'dingy',\n",
       " 'neighbourhood',\n",
       " 'fire',\n",
       " 'painted',\n",
       " 'brasses',\n",
       " 'cleanliness',\n",
       " 'caught',\n",
       " 'pleased',\n",
       " 'passenger',\n",
       " 'east',\n",
       " 'line',\n",
       " 'just',\n",
       " 'point',\n",
       " 'certain',\n",
       " 'block',\n",
       " 'gable',\n",
       " 'showed',\n",
       " 'lower',\n",
       " 'storey',\n",
       " 'discoloured',\n",
       " 'feature',\n",
       " 'prolonged',\n",
       " 'negligence',\n",
       " 'equipped',\n",
       " 'neither',\n",
       " 'nor',\n",
       " 'blistered',\n",
       " 'tramps',\n",
       " 'slouched',\n",
       " 'panels',\n",
       " 'kept',\n",
       " 'upon',\n",
       " 'steps',\n",
       " 'schoolboy',\n",
       " 'tried',\n",
       " 'close',\n",
       " 'generation',\n",
       " 'repair',\n",
       " 'abreast',\n",
       " 'lifted',\n",
       " 'pointed',\n",
       " 'ever',\n",
       " 'companion',\n",
       " 'affirmative',\n",
       " 'mind',\n",
       " 'added',\n",
       " 'very',\n",
       " 'home',\n",
       " 'end',\n",
       " 'three',\n",
       " 'there',\n",
       " 'literally',\n",
       " 'seen',\n",
       " 'folks',\n",
       " 'asleep',\n",
       " 'procession',\n",
       " 'till',\n",
       " 'got',\n",
       " 'state',\n",
       " 'listens',\n",
       " 'begins',\n",
       " 'policeman',\n",
       " 'once',\n",
       " 'figures',\n",
       " 'stumping',\n",
       " 'eastward',\n",
       " 'walk',\n",
       " 'maybe',\n",
       " 'eight',\n",
       " 'ten',\n",
       " 'able',\n",
       " 'cross',\n",
       " 'ran',\n",
       " 'horrible',\n",
       " 'child',\n",
       " 'her',\n",
       " 'ground',\n",
       " 'sounds',\n",
       " 'hear',\n",
       " 'hellish',\n",
       " 'wasn',\n",
       " 'damned',\n",
       " 'gave',\n",
       " 'took',\n",
       " 'collared',\n",
       " 'gentleman',\n",
       " 'already',\n",
       " 'group',\n",
       " 'perfectly',\n",
       " 'look',\n",
       " 'turned',\n",
       " 'family',\n",
       " 'pretty',\n",
       " 'doctor',\n",
       " 'sent',\n",
       " 'worse',\n",
       " 'frightened',\n",
       " 'curious',\n",
       " 'usual',\n",
       " 'cut',\n",
       " 'apothecary',\n",
       " 'particular',\n",
       " 'colour',\n",
       " 'accent',\n",
       " 'emotional',\n",
       " 'rest',\n",
       " 'us',\n",
       " 'turn',\n",
       " 'kill',\n",
       " 'killing',\n",
       " 'question',\n",
       " 'we',\n",
       " 'told',\n",
       " 'make',\n",
       " 'name',\n",
       " 'lose',\n",
       " 'pitching',\n",
       " 'hot',\n",
       " 'women',\n",
       " 'wild',\n",
       " 'harpies',\n",
       " 'hateful',\n",
       " 'middle',\n",
       " 'kind',\n",
       " 'coolness',\n",
       " 'really',\n",
       " 'am',\n",
       " 'wishes',\n",
       " 'scene',\n",
       " 'says',\n",
       " 'figure',\n",
       " 'liked',\n",
       " 'money',\n",
       " 'think',\n",
       " 'carried',\n",
       " 'matter',\n",
       " 'gold',\n",
       " 'balance',\n",
       " 'mention',\n",
       " 'points',\n",
       " 'genuine',\n",
       " 'pointing',\n",
       " 'cellar',\n",
       " 'four',\n",
       " 'open',\n",
       " 'cash',\n",
       " 'myself',\n",
       " 'father',\n",
       " 'passed',\n",
       " 'breakfasted',\n",
       " 'bank',\n",
       " 'believe',\n",
       " 'tut',\n",
       " 'feel',\n",
       " 'yes',\n",
       " 'nobody',\n",
       " 'person',\n",
       " 'celebrated',\n",
       " 'call',\n",
       " 'blackmail',\n",
       " 'suppose',\n",
       " 'paying',\n",
       " 'nose',\n",
       " 'capers',\n",
       " 'house',\n",
       " 'know',\n",
       " 'far',\n",
       " 'vein',\n",
       " 'suddenly',\n",
       " 'don',\n",
       " 'likely',\n",
       " 'happen',\n",
       " 'square',\n",
       " 'delicacy',\n",
       " 'strongly',\n",
       " 'putting',\n",
       " 'questions',\n",
       " 'partakes',\n",
       " 'style',\n",
       " 'starting',\n",
       " 'stone',\n",
       " 'quietly',\n",
       " 'goes',\n",
       " 'bland',\n",
       " 'bird',\n",
       " 'thought',\n",
       " 'knocked',\n",
       " 'head',\n",
       " 'garden',\n",
       " 'rule',\n",
       " 'looks',\n",
       " 'ask',\n",
       " 'continued',\n",
       " 'looking',\n",
       " 'floor',\n",
       " 'none',\n",
       " 'below',\n",
       " 'always',\n",
       " 'must',\n",
       " 'live',\n",
       " 'sure',\n",
       " 'buildings',\n",
       " 'packed',\n",
       " 'ends',\n",
       " 'walked',\n",
       " 'again',\n",
       " 'silence',\n",
       " 'yours',\n",
       " 'harm',\n",
       " 'describe',\n",
       " 'displeasing',\n",
       " 'right',\n",
       " 'disliked',\n",
       " 'scarce',\n",
       " 'why',\n",
       " 'deformed',\n",
       " 'although',\n",
       " 'couldn',\n",
       " 'declare',\n",
       " 'consideration',\n",
       " 'surprised',\n",
       " 'correct',\n",
       " 'touch',\n",
       " 'sullenness',\n",
       " 'pedantically',\n",
       " 'ago',\n",
       " 'young',\n",
       " 'refer',\n",
       " 'heart',\n",
       " 'shake',\n",
       " 'bachelor',\n",
       " 'sat',\n",
       " 'relish',\n",
       " 'meal',\n",
       " 'divinity',\n",
       " 'desk',\n",
       " 'until',\n",
       " 'neighbouring',\n",
       " 'rang',\n",
       " 'twelve',\n",
       " 'soberly',\n",
       " 'gratefully',\n",
       " 'however',\n",
       " 'room',\n",
       " 'opened',\n",
       " 'safe',\n",
       " 'private',\n",
       " 'endorsed',\n",
       " 'envelope',\n",
       " 'clouded',\n",
       " 'brow',\n",
       " 'charge',\n",
       " 'now',\n",
       " 'refused',\n",
       " 'assistance',\n",
       " 'making',\n",
       " 'd',\n",
       " 'c',\n",
       " 'l',\n",
       " 'r',\n",
       " 'pass',\n",
       " 'benefactor',\n",
       " 'unexplained',\n",
       " 'period',\n",
       " 'exceeding',\n",
       " 'calendar',\n",
       " 'months',\n",
       " 'step',\n",
       " 'shoes',\n",
       " 'further',\n",
       " 'delay',\n",
       " 'free',\n",
       " 'burthen',\n",
       " 'beyond',\n",
       " 'payment',\n",
       " 'sums',\n",
       " 'members',\n",
       " 'eyesore',\n",
       " 'both',\n",
       " 'sane',\n",
       " 'immodest',\n",
       " 'knowledge',\n",
       " 'attributes',\n",
       " 'shifting',\n",
       " 'insubstantial',\n",
       " 'leaped',\n",
       " 'replaced',\n",
       " 'obnoxious',\n",
       " 'fear',\n",
       " 'disgrace',\n",
       " 'blew',\n",
       " 'direction',\n",
       " 'cavendish',\n",
       " 'medicine',\n",
       " 'crowding',\n",
       " 'patients',\n",
       " 'welcomed',\n",
       " 'stage',\n",
       " 'healthy',\n",
       " 'dapper',\n",
       " 'faced',\n",
       " 'shock',\n",
       " 'hair',\n",
       " 'boisterous',\n",
       " 'decided',\n",
       " 'chair',\n",
       " 'geniality',\n",
       " 'somewhat',\n",
       " 'mates',\n",
       " 'school',\n",
       " 'college',\n",
       " 'thorough',\n",
       " 'themselves',\n",
       " 'thoroughly',\n",
       " 'rambling',\n",
       " 'preoccupied',\n",
       " 'oldest',\n",
       " 'chuckled',\n",
       " 'interest',\n",
       " 'take',\n",
       " 'unscientific',\n",
       " 'damon',\n",
       " 'pythias',\n",
       " 'spirit',\n",
       " 'temper',\n",
       " 'differed',\n",
       " 'science',\n",
       " 'scientific',\n",
       " 'passions',\n",
       " 'heard',\n",
       " 'amount',\n",
       " 'dark',\n",
       " 'tossed',\n",
       " 'hours',\n",
       " 'large',\n",
       " 'toiling',\n",
       " 'besieged',\n",
       " 'conveniently',\n",
       " 'near',\n",
       " 'dwelling',\n",
       " 'digging',\n",
       " 'touched',\n",
       " 'imagination',\n",
       " 'engaged',\n",
       " 'gross',\n",
       " 'curtained',\n",
       " 'scroll',\n",
       " 'pictures',\n",
       " 'field',\n",
       " 'swiftly',\n",
       " 'trod',\n",
       " 'regardless',\n",
       " 'screams',\n",
       " 'dreaming',\n",
       " 'plucked',\n",
       " 'apart',\n",
       " 'sleeper',\n",
       " 'lo',\n",
       " 'stand',\n",
       " 'power',\n",
       " 'phases',\n",
       " 'haunted',\n",
       " 'sleeping',\n",
       " 'houses',\n",
       " 'move',\n",
       " 'dizziness',\n",
       " 'labyrinths',\n",
       " 'crush',\n",
       " 'leave',\n",
       " 'melted',\n",
       " 'eyes',\n",
       " 'thus',\n",
       " 'apace',\n",
       " 'curiosity',\n",
       " 'behold',\n",
       " 'mystery',\n",
       " 'lighten',\n",
       " 'perhaps',\n",
       " 'roll',\n",
       " 'altogether',\n",
       " 'habit',\n",
       " 'mysterious',\n",
       " 'things',\n",
       " 'examined',\n",
       " 'preference',\n",
       " 'bondage',\n",
       " 'worth',\n",
       " 'seeing',\n",
       " 'mercy',\n",
       " 'enduring',\n",
       " 'hatred',\n",
       " 'haunt',\n",
       " 'noon',\n",
       " 'rewarded',\n",
       " 'fine',\n",
       " 'frost',\n",
       " 'streets',\n",
       " 'ballroom',\n",
       " 'drawing',\n",
       " 'regular',\n",
       " 'pattern',\n",
       " 'shadow',\n",
       " 'low',\n",
       " 'growl',\n",
       " 'round',\n",
       " 'rumour',\n",
       " 'approach',\n",
       " 'minutes',\n",
       " 'footstep',\n",
       " 'nightly',\n",
       " 'accustomed',\n",
       " 'quaint',\n",
       " 'effect',\n",
       " 'footfalls',\n",
       " 'single',\n",
       " 'sharply',\n",
       " 'superstitious',\n",
       " 'success',\n",
       " 'nearer',\n",
       " 'deal',\n",
       " 'dressed',\n",
       " 'distance',\n",
       " 'against',\n",
       " 'crossing',\n",
       " 'save',\n",
       " 'stepped',\n",
       " 'shoulder',\n",
       " 'intake',\n",
       " 'answered',\n",
       " 'coolly',\n",
       " 'gaunt',\n",
       " 'meeting',\n",
       " 'admit',\n",
       " 'fronted',\n",
       " 'stared',\n",
       " 'useful',\n",
       " '_à',\n",
       " 'propos_',\n",
       " 'grunted',\n",
       " 'description',\n",
       " 'whose',\n",
       " 'echoed',\n",
       " 'anger',\n",
       " 'lied',\n",
       " 'fitting',\n",
       " 'snarled',\n",
       " 'savage',\n",
       " 'laugh',\n",
       " 'quickness',\n",
       " 'unlocked',\n",
       " 'awhile',\n",
       " 'pausing',\n",
       " 'debating',\n",
       " 'class',\n",
       " 'pale',\n",
       " 'impression',\n",
       " 'nameable',\n",
       " 'malformation',\n",
       " 'borne',\n",
       " 'murderous',\n",
       " 'timidity',\n",
       " 'husky',\n",
       " 'unknown',\n",
       " 'disgust',\n",
       " 'regarded',\n",
       " 'perplexed',\n",
       " 'transfigures',\n",
       " 'continent',\n",
       " 'poor',\n",
       " 'harry',\n",
       " 'read',\n",
       " 'new',\n",
       " 'ancient',\n",
       " 'decayed',\n",
       " 'flats',\n",
       " 'sorts',\n",
       " 'conditions',\n",
       " 'architects',\n",
       " 'shady',\n",
       " 'entire',\n",
       " 'wealth',\n",
       " 'plunged',\n",
       " 'stopped',\n",
       " 'comfortable',\n",
       " 'paved',\n",
       " 'flags',\n",
       " 'bright',\n",
       " 'furnished',\n",
       " 'costly',\n",
       " 'cabinets',\n",
       " 'oak',\n",
       " 'fender',\n",
       " 'fancy',\n",
       " 'speak',\n",
       " 'pleasantest',\n",
       " 'heavy',\n",
       " 'felt',\n",
       " 'rare',\n",
       " 'distaste',\n",
       " 'gloom',\n",
       " 'flickering',\n",
       " 'uneasy',\n",
       " 'announce',\n",
       " 'dissecting',\n",
       " 'master',\n",
       " 'repose',\n",
       " 'musingly',\n",
       " 'orders',\n",
       " 'obey',\n",
       " '_dines_',\n",
       " 'homeward',\n",
       " 'misgives',\n",
       " 'law',\n",
       " 'limitations',\n",
       " 'ghost',\n",
       " '_pede',\n",
       " 'self',\n",
       " 'love',\n",
       " 'condoned',\n",
       " 'fault',\n",
       " 'scared',\n",
       " 'brooded',\n",
       " 'past',\n",
       " 'groping',\n",
       " 'corners',\n",
       " 'chance',\n",
       " 'iniquity',\n",
       " 'fairly',\n",
       " 'blameless',\n",
       " 'ill',\n",
       " 'raised',\n",
       " 'gratitude',\n",
       " 'avoided',\n",
       " 'secrets',\n",
       " 'compared',\n",
       " 'worst',\n",
       " 'sunshine',\n",
       " 'cannot',\n",
       " 'turns',\n",
       " 'creature',\n",
       " 'thief',\n",
       " 'danger',\n",
       " 'suspects',\n",
       " 'existence',\n",
       " 'impatient',\n",
       " 'inherit',\n",
       " 'shoulders',\n",
       " 'clear',\n",
       " 'excellent',\n",
       " 'dinners',\n",
       " 'cronies',\n",
       " 'judges',\n",
       " 'contrived',\n",
       " 'arrangement',\n",
       " 'befallen',\n",
       " 'scores',\n",
       " 'loved',\n",
       " 'detain',\n",
       " 'hearted',\n",
       " 'loose',\n",
       " 'tongued',\n",
       " 'unobtrusive',\n",
       " 'minds',\n",
       " 'expense',\n",
       " 'exception',\n",
       " 'smooth',\n",
       " 'cast',\n",
       " 'capacity',\n",
       " 'wanting',\n",
       " 'latter',\n",
       " 'observer',\n",
       " 'gathered',\n",
       " 'topic',\n",
       " 'distasteful',\n",
       " 'gaily',\n",
       " 'unfortunate',\n",
       " 'hide',\n",
       " 'needn',\n",
       " 'frown',\n",
       " 'mean',\n",
       " 'blatant',\n",
       " 'ruthlessly',\n",
       " 'disregarding',\n",
       " 'certainly',\n",
       " 'trifle',\n",
       " 'tell',\n",
       " 'learning',\n",
       " 'lips',\n",
       " 'blackness',\n",
       " 'understand',\n",
       " 'position',\n",
       " 'situated',\n",
       " 'talking',\n",
       " 'trusted',\n",
       " 'downright',\n",
       " 'rid',\n",
       " 'getting',\n",
       " 'sincerely',\n",
       " 'bear',\n",
       " 'pleaded',\n",
       " 'longer',\n",
       " 'year',\n",
       " 'month',\n",
       " 'startled',\n",
       " 'singular',\n",
       " 'notable',\n",
       " 'victim',\n",
       " 'details',\n",
       " 'maid',\n",
       " 'living',\n",
       " 'eleven',\n",
       " 'fog',\n",
       " 'rolled',\n",
       " 'cloudless',\n",
       " 'lane',\n",
       " 'overlooked',\n",
       " 'lit',\n",
       " 'dream',\n",
       " 'streaming',\n",
       " 'tears',\n",
       " 'narrated',\n",
       " 'peace',\n",
       " 'aged',\n",
       " 'advancing',\n",
       " 'meet',\n",
       " 'paid',\n",
       " 'speech',\n",
       " 'bowed',\n",
       " 'politeness',\n",
       " 'watch',\n",
       " 'innocent',\n",
       " 'dislike',\n",
       " 'flame',\n",
       " 'brandishing',\n",
       " 'hurt',\n",
       " 'bounds',\n",
       " 'earth',\n",
       " 'ape',\n",
       " 'trampling',\n",
       " 'hailing',\n",
       " 'storm',\n",
       " 'blows',\n",
       " 'bones',\n",
       " 'audibly',\n",
       " 'shattered',\n",
       " 'sights',\n",
       " 'fainted',\n",
       " 'murderer',\n",
       " 'deed',\n",
       " 'wood',\n",
       " 'stress',\n",
       " 'insensate',\n",
       " 'gutter',\n",
       " 'purse',\n",
       " 'cards',\n",
       " 'papers',\n",
       " 'sealed',\n",
       " 'stamped',\n",
       " 'probably',\n",
       " 'circumstances',\n",
       " 'lip',\n",
       " 'dress',\n",
       " 'grave',\n",
       " 'station',\n",
       " 'exclaimed',\n",
       " 'officer',\n",
       " 'possible',\n",
       " 'professional',\n",
       " 'ambition',\n",
       " 'briefly',\n",
       " 'quailed',\n",
       " 'presented',\n",
       " 'particularly',\n",
       " 'chocolate',\n",
       " 'continually',\n",
       " 'charging',\n",
       " 'embattled',\n",
       " 'vapours',\n",
       " 'beheld',\n",
       " 'marvelous',\n",
       " 'degrees',\n",
       " 'conflagration',\n",
       " 'haggard',\n",
       " 'shaft',\n",
       " 'daylight',\n",
       " 'swirling',\n",
       " 'wreaths',\n",
       " 'dismal',\n",
       " 'glimpses',\n",
       " 'slatternly',\n",
       " 'passengers',\n",
       " 'afresh',\n",
       " 'mournful',\n",
       " 'reinvasion',\n",
       " 'nightmare',\n",
       " 'glanced',\n",
       " 'conscious',\n",
       " 'terror',\n",
       " 'officers',\n",
       " 'assail',\n",
       " 'palace',\n",
       " 'eating',\n",
       " 'numbers',\n",
       " 'twopenny',\n",
       " 'ragged',\n",
       " 'huddled',\n",
       " 'different',\n",
       " 'glass',\n",
       " 'settled',\n",
       " 'umber',\n",
       " 'heir',\n",
       " 'ivory',\n",
       " 'silvery',\n",
       " 'evil',\n",
       " 'smoothed',\n",
       " 'hypocrisy',\n",
       " 'late',\n",
       " 'habits',\n",
       " 'absent',\n",
       " 'rooms',\n",
       " 'impossible',\n",
       " 'inspector',\n",
       " 'newcomen',\n",
       " 'scotland',\n",
       " 'yard',\n",
       " 'flash',\n",
       " 'trouble',\n",
       " 'glances',\n",
       " 'extent',\n",
       " 'filled',\n",
       " 'silver',\n",
       " 'napery',\n",
       " 'elegant',\n",
       " 'hung',\n",
       " 'walls',\n",
       " 'gift',\n",
       " 'carpets',\n",
       " 'agreeable',\n",
       " 'lock',\n",
       " 'drawers',\n",
       " 'pile',\n",
       " 'grey',\n",
       " 'embers',\n",
       " 'butt',\n",
       " 'green',\n",
       " 'book',\n",
       " 'action',\n",
       " 'clinched',\n",
       " 'suspicions',\n",
       " 'delighted',\n",
       " 'visit',\n",
       " 'several',\n",
       " 'thousand',\n",
       " 'lost',\n",
       " 'above',\n",
       " 'accomplishment',\n",
       " 'familiars',\n",
       " 'traced',\n",
       " 'photographed',\n",
       " 'widely',\n",
       " 'haunting',\n",
       " 'fugitive',\n",
       " 'impressed',\n",
       " 'afternoon',\n",
       " 'admitted',\n",
       " 'offices',\n",
       " 'bought',\n",
       " 'heirs',\n",
       " 'anatomical',\n",
       " 'changed',\n",
       " 'destination',\n",
       " 'quarters',\n",
       " 'straw',\n",
       " 'falling',\n",
       " 'foggy',\n",
       " 'flight',\n",
       " 'covered',\n",
       " 'fitted',\n",
       " 'barred',\n",
       " 'grate',\n",
       " 'lie',\n",
       " 'thickly',\n",
       " 'bade',\n",
       " 'news',\n",
       " 'crying',\n",
       " 'bind',\n",
       " 'honour',\n",
       " 'feverish',\n",
       " 'trial',\n",
       " 'appear',\n",
       " 'share',\n",
       " 'advise',\n",
       " 'loss',\n",
       " 'wisely',\n",
       " 'exposed',\n",
       " 'selfishness',\n",
       " 'relieved',\n",
       " 'labour',\n",
       " 'means',\n",
       " 'escape',\n",
       " 'placed',\n",
       " 'intimacy',\n",
       " 'postmark',\n",
       " 'handed',\n",
       " 'consider',\n",
       " 'mouth',\n",
       " ...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_43.flatMap(clean_split_line).map(lambda x: x.lower()).distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b13b79",
   "metadata": {},
   "source": [
    "QX \n",
    "\n",
    "* Generate an RDD that contains the frequency of each word in `book_43`. Call the variable `book_43_counts`\n",
    "* Since there colleciton may contain a large number of words, it would be improdent to collect all the wods on the same machine. Instead, display the counts of first word in your list . \n",
    "* Given the random nature of this operaiton, result may be different. For me, the first entry was\n",
    "  * You can only use operarations or actions to answer the question. \n",
    "  * Code that uses methods such as `some_rdd.X().Y().Z()...` is allowed\n",
    "  * Code that uses function such as `some_func(...)` is not allowed\n",
    "\n",
    "```\n",
    "[('project', 88)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42729b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('project', 88)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_43_counts = book_43.flatMap(clean_split_line).map(lambda x: (x.lower(),1)).reduceByKey(lambda x,y: x+y)\n",
    "book_43_counts.take(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee4534c",
   "metadata": {},
   "source": [
    "QX Sort book_43_counts and print the 20 most common words in book_43. \n",
    "  * Hint: function sortByKey sort a collection of tuples on the first element element of the list. Make sure you instead sort on the second of each element in `book_43_counts`\n",
    "  * You can only use operarations or actions to answer the question. \n",
    "  * Code that uses methods such as `some_rdd.X().Y().Z()...` is allowed\n",
    "  * Code that uses function such as `some_func(...)` is not allowed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d51b8ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1807, 'the'),\n",
       " (1068, 'of'),\n",
       " (1043, 'and'),\n",
       " (726, 'to'),\n",
       " (686, 'a'),\n",
       " (646, 'i'),\n",
       " (485, 'in'),\n",
       " (471, 'was'),\n",
       " (392, 'that'),\n",
       " (384, 'he')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_43_counts.map(lambda x:(x[1], x[0])).sortByKey(ascending=False).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13420b09",
   "metadata": {},
   "source": [
    "QX \n",
    "Note that the most frequent workds in `book_43_counts` include stop workds such as `of`, `the`, `and`, etc.\n",
    "It would be foolish to compare document based on whether or not they contain such stop words. As such, it's common to remove such stop words.\n",
    "The librarary `sklearn.feature_extraction` provides access to a collection of english stop words. Those are accessible using the following snippet\n",
    "\n",
    "```\n",
    "from sklearn.feature_extraction import stop_words\n",
    "stop_words.ENGLISH_STOP_WORDS\n",
    "```\n",
    "\n",
    "* Explore the frozen set data structure (a set that you cannot modify)  by print any 10 words from it. \n",
    " * Hint conver the frozen set to something you can subscript\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e0ad996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['once',\n",
       " 'thru',\n",
       " 'sometimes',\n",
       " 'seem',\n",
       " 'give',\n",
       " 'everything',\n",
       " 'upon',\n",
       " 'hereby',\n",
       " 'never',\n",
       " 'formerly']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "list(ENGLISH_STOP_WORDS)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625eb521",
   "metadata": {},
   "source": [
    "QX\n",
    "\n",
    "filter out the words in book_43_counts by removing those that appear in the ENGLISH_STOP_WORDS.\n",
    "Save the results to a new variable called `book_43_counts_filtered`\n",
    "  * You can only use operarations or actions to answer the question. \n",
    "  * Code that uses methods such as `some_rdd.X().Y().Z()...` is allowed\n",
    "  * Code that uses function such as `some_func(...)` is not allowed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5602b4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_43_counts_filtered = book_43_counts.filter(lambda x: x[0] not in ENGLISH_STOP_WORDS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0b3a80",
   "metadata": {},
   "source": [
    "QX \n",
    "how many words left in book_43_counts_filtered after removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5bdf083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4296"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_43_counts_filtered.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ffd755",
   "metadata": {},
   "source": [
    "QX Write a function, call it `process_RDD`  that combines the relevant steps above so that we can apply them to the four remaining books. Your function should take a text file as input and:\n",
    " * Read in the file as a textRDD\n",
    " * Clean and split the line\n",
    " * Filter our stop words\n",
    " * returns an word count RDD where each item is tuple of word and its count.\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eff5d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_RDD(file_path):\n",
    "    book_rdd = sc.textFile(file_path)\n",
    "    book_rdd_counts = book_rdd.flatMap(clean_split_line).map(lambda x: (x.lower(),1)).reduceByKey(lambda x,y: x+y)\n",
    "    book_rdd_counts_filtered = book_rdd_counts.filter(lambda x: x[0] not in ENGLISH_STOP_WORDS)\n",
    "    return book_rdd_counts_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba59c9c5",
   "metadata": {},
   "source": [
    "QX apply the funciton `process_RDD` to book_84, book_398 and book_3296 and the results the variables book_84_counts_filtered, book_398_counts_filtered and book_3296_counts_filtered respectively and print the number of distinct words after filtering stop words in each of these books \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "08a24f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book 84 count is:  7016\n",
      "Book 398 count is:  2421\n",
      "Book 3296 count is:  7293\n"
     ]
    }
   ],
   "source": [
    "book_84_counts_filtered = process_RDD(\"data/84.txt\")\n",
    "book_398_counts_filtered = process_RDD(\"data/398.txt\")\n",
    "book_3296_counts_filtered = process_RDD(\"data/3296.txt\")\n",
    "\n",
    "print(\"Book 84 count is: \", book_84_counts_filtered.count())\n",
    "print(\"Book 398 count is: \", book_398_counts_filtered.count())\n",
    "print(\"Book 3296 count is: \", book_3296_counts_filtered.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb9680f",
   "metadata": {},
   "source": [
    "QX. In the prelude, we discussed evaluating the similarity between two texts using the number of words they share. If that holds, book_398 and book_3296, which both talk about religion will have more words in common than, say, book_84 and book_398. Test this hypothesis by writing code that compares and prints the number of words shared between first book_398 and book_3296 and then between book_84 and book_398.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ac6b73e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words shared between book_398 and book_3296 is:\n",
      "1790\n",
      "number of words shared between book_84 and book_3296 is:\n",
      "3608\n"
     ]
    }
   ],
   "source": [
    "print(\"number of words shared between book_398 and book_3296 is:\")\n",
    "print(book_398_counts_filtered.map(lambda x: x[0]).intersection(book_3296_counts_filtered.map(lambda x: x[0])).count())\n",
    "print(\"number of words shared between book_84 and book_3296 is:\")\n",
    "print(book_84_counts_filtered.map(lambda x: x[0]).intersection(book_3296_counts_filtered.map(lambda x: x[0])).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9f326",
   "metadata": {},
   "source": [
    "QX. mBased on the above, do you think counting the number of shared words is a good idea? Justify your answer?\n",
    "* Hint: what's common to both book_84 and book_3296? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6587ae14",
   "metadata": {},
   "source": [
    "######  ANSWER\n",
    "Not a good idea. Both book_84 and book_3296 are moch larger than the other books are most likely to have more words in common just by virtue of their length?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f8f857",
   "metadata": {},
   "source": [
    "Part II \n",
    "\n",
    "Another appraoch to estimating similarity consits of computing the Euclidean distance across a set of words. For example Suppose we have 3 books A, B and C with the following ocunts for words `evolution`, `DNA`, `biology` and `finance`. \n",
    "```python \n",
    "A = [4, 9, 6, 8]\n",
    "B = [3, 7, 7, 10]\n",
    "C = [15, 10, 1, 1]\n",
    "```\n",
    "note that although all workds contain exactly the same four workds, the number of times these words is used may be indicative of thier topic, for example, documents A and B are more likely to be business related since the work finance occours frequently (8 and 10 times respectively). The third may be a technical document since it focuse more technical workds (evolution and DNA) and less on finance.\n",
    "\n",
    "The Euclidean distance, whcih can be computed suing scikit usng the snippet below is more indicative of topic-relatedness between the two documents.\n",
    "cpython\n",
    "from scipy.spatial.distance import euclidean \n",
    "print(f\"The Euclidean distance between A and B is: {euclidean(A, B)}\")\n",
    "\n",
    "print(f\"The Euclidean distance between A and C is: {euclidean(A, C)}\")\n",
    "\n",
    "print(f\"The Euclidean distance between B and C is: {euclidean(B, C)}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7838f937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Euclidean distance between A and B is: 3.1622776601683795\n",
      "The Euclidean distance between A and C is: 14.0\n",
      "The Euclidean distance between B and C is: 16.431676725154983\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import euclidean \n",
    "\n",
    "A = [4, 9, 6, 8]\n",
    "B = [3, 7, 7, 10]\n",
    "C = [15, 10, 1, 1]\n",
    "\n",
    "print(f\"The Euclidean distance between A and B is: {euclidean(A, B)}\")\n",
    "print(f\"The Euclidean distance between A and C is: {euclidean(A, C)}\")\n",
    "print(f\"The Euclidean distance between B and C is: {euclidean(B, C)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abdc35e",
   "metadata": {},
   "source": [
    "QX To test whether the Euclidean distance is a good approach to identify similar clusters, we need first identify the set of words across which we will compare the documents. Here, we will explore the words that are common to all 4 documents. We will store the data in a martrix called `counts_matrix`.\n",
    "\n",
    "Start by finding the words that are common to all four documents after stop-word filtering and store the counts for each word in a column of `counts_matrix`. \n",
    "\n",
    "To take the previous example, you can generate an emtpy matrix with 3 lines (books A, B and X) and 4 columns (words `evolution`, `DNA`, `biology` and `finance`) using the following code.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "counts_matrix = np.zeros([3,4])\n",
    "```\n",
    "\n",
    "After generting the counts, you can fill the counts for a document, say A, using the following code:\n",
    "\n",
    "```python\n",
    "counts_matrix[0, :] = [4, 9, 6, 8] \n",
    "```\n",
    "* other than for buidling the counts into `counts_matrix` you shoud exclusively use operarations or actions on the RDD to answer the question. \n",
    "  * Code that uses methods such as `some_rdd.X().Y().Z()...` is allowed\n",
    "  * Code that uses function such as `some_func(...)` is not allowed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c3cae946",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = (\n",
    "book_43_counts_filtered.\n",
    "    map(lambda x: x[0]).\n",
    "    intersection(book_84_counts_filtered.map(lambda x: x[0])).\n",
    "    intersection(book_398_counts_filtered.map(lambda x: x[0])).\n",
    "    intersection(book_3296_counts_filtered.map(lambda x: x[0]))\n",
    ").collect()\n",
    "counts_matrix = np.zeros([4,len(common_words)])\n",
    "\n",
    "x = book_43_counts_filtered.filter(lambda x: x[0] in common_words).collect()\n",
    "counts_matrix[0,:]= [x[1] for x in x]\n",
    "\n",
    "x = book_84_counts_filtered.filter(lambda x: x[0] in common_words).collect()\n",
    "counts_matrix[1,:]= [x[1] for x in x]\n",
    "\n",
    "x = book_398_counts_filtered.filter(lambda x: x[0] in common_words).collect()\n",
    "counts_matrix[2,:]= [x[1] for x in x]\n",
    "\n",
    "x = book_3296_counts_filtered.filter(lambda x: x[0] in common_words).collect()\n",
    "counts_matrix[3,:]= [x[1] for x in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124bcdd8",
   "metadata": {},
   "source": [
    "QX. Compute the Euclidean distance between book_398 and book_3296, which both talk about religion and book_84 and book_398. What do you conclude about using the Euclidean distance for comparing documents. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7b6a81dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Euclidean distance between        book_398 and book_3296 is: 1470.8415958219293\n",
      "The Euclidean distance between       book_84 and book_398 is: 867.2508287687017\n"
     ]
    }
   ],
   "source": [
    "print(f\"The Euclidean distance between  \\\n",
    "      book_398 and book_3296 is: {euclidean(counts_matrix[2], counts_matrix[3])}\")\n",
    "print(f\"The Euclidean distance between \\\n",
    "      book_84 and book_398 is: {euclidean(counts_matrix[1], counts_matrix[2])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89981b46",
   "metadata": {},
   "source": [
    "Again Simplly due to the fact that both same more words, the counts are biaed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4e54e6",
   "metadata": {},
   "source": [
    "QX \n",
    "Bonus question (5 points): Can you think of a few things we could do to improve similarity between documents that pertain to the same topic. Jutify your answer without given codem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8c6de1",
   "metadata": {},
   "source": [
    "* normalize the data by the total number of words in the bool\n",
    "* selecting words that are common to all four biases words that are common to one topic (ex. Religion). All thos words, whcih are highly specific are missing.\n",
    "* Ultimately, words alone don't mean much. If a book uses the words Religion and Dogma  and the second book uses the words faith and belief, the match would be nil. If, howeever, we could use synonyms, we would know that that all four 4 words are synonymouls. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedf1d74",
   "metadata": {},
   "source": [
    "Part III\n",
    "\n",
    "In this part we will build some basic analytics from data pertaining to all flights in the US petaining to US Airliners. Here, you should use exclusively `SparkDatFrames. In one month.\n",
    "\n",
    "Load the file `flight_info.csv` into a spark DataFrame. \n",
    "\n",
    "  * note that you will have to create sparkSession prior to loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad5e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = SparkSession(sc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
